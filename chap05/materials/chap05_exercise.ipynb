{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5回講義 演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目次\n",
    "\n",
    "課題. 畳み込みニューラルネットワーク(Convolutional Neural Networks)の実装と学習\n",
    "    1. MNISTデータセットの読み込み\n",
    "    2. 畳み込みとプーリング in tensorflow\n",
    "        - 2.1. 畳み込み: tf.nn.conv2d\n",
    "        - 2.2. プーリング: tf.nn.max_pool, tf.nn.avg_pool, etc.\n",
    "    2. 畳み込みとプーリング in tensorflow\n",
    "        - 3.1. 畳み込み層\n",
    "        - 3.2. プーリング層\n",
    "        - 3.3.平滑化層（4次元->2次元）\n",
    "        - 3.4. 全結合層\n",
    "    4. 計算グラフ構築 & パラメータの更新設定\n",
    "    5. 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題. 畳み込みニューラルネットワーク(Convolutional Neural Networks)の実装と学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MNISTデータセットの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込みニューラルネットワーク(CNN)ではMNISTを4次元テンソルとして扱います。MNISTは縦と横のサイズが28×28で、チャネル数は1となるので、画像サイズは(バッチサイズ, 28,28, 1)となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "\r",
      "    8192/11490434 [..............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "   24576/11490434 [..............................] - ETA: 28s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "   57344/11490434 [..............................] - ETA: 24s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  122880/11490434 [..............................] - ETA: 16s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  262144/11490434 [..............................] - ETA: 10s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  507904/11490434 [>.............................] - ETA: 6s \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1048576/11490434 [=>............................] - ETA: 3s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1638400/11490434 [===>..........................] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3219456/11490434 [=======>......................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4415488/11490434 [==========>...................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5251072/11490434 [============>.................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6823936/11490434 [================>.............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8396800/11490434 [====================>.........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9953280/11490434 [========================>.....] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, t_train), (x_valid, t_valid) = mnist.load_data()\n",
    "\n",
    "x_train = (x_train.reshape(-1, 28, 28, 1) / 255).astype(np.float32)\n",
    "x_valid = (x_valid.reshape(-1, 28, 28, 1) / 255).astype(np.float32)\n",
    "\n",
    "t_train = np.eye(10)[t_train].astype(np.float32)\n",
    "t_valid = np.eye(10)[t_valid].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 畳み込みとプーリング in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. 畳み込み: tf.nn.conv2d [\\[link\\]](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 入力または隠れ層$X_{i, j}^{k}$\n",
    "    - 次元数4$(n,i,j,k)$\n",
    "        - $n$：バッチサイズ\n",
    "        - $i$：入力の行数\n",
    "        - $j$：入力の列数\n",
    "        - $k$：入力のチャネル数\n",
    "- 畳み込みのフィルタ（重み）$W_{i,j}^{k,l}$\n",
    "    - 次元数4$(i,j,k,l)$\n",
    "        - $i$: フィルタの行数\n",
    "        - $j$: フィルタの列数\n",
    "        - $k$: 入力のチャネル数\n",
    "        - $l$: 出力のチャネル数(フィルタ数)\n",
    "    - ストライド：フィルタを適用する位置の間隔\n",
    "    - ゼロパディング：入力の周りに値0の縁を加えます\n",
    "        - 入力のサイズを保つ為、フィルタの縦or横の次元が$F$のときパディング数を$(F-1)/2$とします。\n",
    "- フィルタ後のサイズは、入力の縦or横の次元数$N$、フィルタの縦or横の次元数$F$、ストライドの縦or横の量$S$で決まります。\n",
    "    - $(N-F)/S+1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 畳み込みの適用例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# 入力 (4次元)\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "# サンプル画像\n",
    "sample_image = np.array([[1, 1, 1, 0, 0],\n",
    "                         [0, 1, 1, 1, 0],\n",
    "                         [0, 0, 1, 1, 1],\n",
    "                         [0, 0, 1, 1, 0],\n",
    "                         [0, 1, 1, 0, 0]]\n",
    "                       ).astype('float32').reshape(1, 5, 5, 1)  # バッチサイズ x 高さ x 幅 x チャンネル数\n",
    "\n",
    "# フィルタ\n",
    "W = np.array([[1, 0, 1],\n",
    "              [0, 1, 0],\n",
    "              [1, 0, 1]]).astype('float32').reshape(3, 3, 1, 1) # 高さ x 幅 x 入力チャンネル数　x 出力チャンネル数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 5, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [0.]\n",
      "   [0.]]]]\n"
     ]
    }
   ],
   "source": [
    "print(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.]]\n",
      "\n",
      "  [[0.]]\n",
      "\n",
      "  [[1.]]]\n",
      "\n",
      "\n",
      " [[[0.]]\n",
      "\n",
      "  [[1.]]\n",
      "\n",
      "  [[0.]]]\n",
      "\n",
      "\n",
      " [[[1.]]\n",
      "\n",
      "  [[0.]]\n",
      "\n",
      "  [[1.]]]]\n"
     ]
    }
   ],
   "source": [
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 畳み込み1\n",
    "\n",
    "- ストライド: (1, 1)\n",
    "- パディング: なし ('VALID')\n",
    "- 出力のサイズ: (5-3)/1+1=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 3. 4.]\n",
      " [2. 4. 3.]\n",
      " [2. 3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "convoluted_image = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='VALID')  # strides: [1, 高さ, 幅, 1]\n",
    "# 'VALID' means no zero padding\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 畳み込み2\n",
    "\n",
    "- ストライド: (2, 2)\n",
    "- パディング: なし\n",
    "- 出力のサイズ: (5-3)/2+1=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 4.]\n",
      " [2. 4.]]\n"
     ]
    }
   ],
   "source": [
    "convoluted_image = tf.nn.conv2d(x, W, strides=[1,2,2,1], padding='VALID')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 畳み込み3\n",
    "- ストライド: (1, 1)\n",
    "- パディング: (1, 1) 出力サイズが入力と同じになるように\n",
    "- 出力のサイズ: (5-3+2)/1+1=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 2. 3. 1. 1.]\n",
      " [1. 4. 3. 4. 1.]\n",
      " [1. 2. 4. 3. 3.]\n",
      " [1. 2. 3. 4. 1.]\n",
      " [0. 2. 2. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "convoluted_image = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "# 'SAME' means we do zero padding\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 畳み込みの演習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# 入力 (4次元)\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "# サンプル画像\n",
    "sample_image = np.array([[1, 1, 1, 0, 0, 1, 0],\n",
    "                         [0, 1, 0, 1, 0, 1, 1],\n",
    "                         [1, 0, 1, 1, 1, 0, 1],\n",
    "                         [0, 0, 1, 1, 0, 1, 1],\n",
    "                         [1, 1, 1, 1, 0, 0, 1],\n",
    "                         [0, 1, 1, 1, 1, 1, 1],\n",
    "                         [0, 1, 1, 0, 0, 1, 0]]\n",
    "                       ).astype('float32').reshape(1, 7, 7, 1)\n",
    "\n",
    "# フィルタ\n",
    "W = np.array([[1, 0, 1],\n",
    "              [0, 1, 0],\n",
    "              [1, 0, 1]]).astype('float32').reshape(3, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 畳み込み1\n",
    "\n",
    "- ストライド: (1, 1)\n",
    "- パディング: なし ('VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5. 2. 4. 2. 3.]\n",
      " [1. 4. 2. 5. 2.]\n",
      " [4. 4. 4. 2. 4.]\n",
      " [3. 4. 4. 4. 3.]\n",
      " [4. 4. 3. 3. 2.]]\n"
     ]
    }
   ],
   "source": [
    "convoluted_image = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='VALID')#WRITE ME\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 畳み込み2\n",
    "\n",
    "- ストライド: (2, 2)\n",
    "- パディング: なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5. 4. 3.]\n",
      " [4. 4. 4.]\n",
      " [4. 3. 2.]]\n"
     ]
    }
   ],
   "source": [
    "convoluted_image = tf.nn.conv2d(x, W, strides=[1,2,2,1], padding='VALID')#WRITE ME\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 畳み込み3\n",
    "\n",
    "- ストライド: (1, 1)\n",
    "- パディング: (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 1. 3. 0. 2. 2. 1.]\n",
      " [1. 5. 2. 4. 2. 3. 2.]\n",
      " [2. 1. 4. 2. 5. 2. 3.]\n",
      " [1. 4. 4. 4. 2. 4. 1.]\n",
      " [2. 3. 4. 4. 4. 3. 3.]\n",
      " [2. 4. 4. 3. 3. 2. 2.]\n",
      " [1. 2. 3. 2. 2. 3. 1.]]\n"
     ]
    }
   ],
   "source": [
    "convoluted_image = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')#WRITE ME\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(7,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. プーリング: tf.nn.max_pool \\[[link\\]](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool), tf.nn.avg_pool \\[[link\\]](https://www.tensorflow.org/api_docs/python/tf/nn/avg_pool), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- プーリングには次の種類があります。\n",
    "    - Max pooling\n",
    "    - Sum pooling\n",
    "    - Mean pooling\n",
    "    - その他Lpプーリングなど\n",
    "- 畳み込みと同様、ストライドやパディングも考えることがあります。\n",
    "- プーリング後のサイズは、入力の縦or横の次元数$N$、ウィンドウの縦or横の次元数$W$、ストライドの縦or横の量$S$で決まります。\n",
    "    - $(N-W+1)/S$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プーリングの適用例 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# 入力\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "sample_image = np.array([[77, 80, 82, 78, 70],\n",
    "                         [83, 78, 80, 83, 82],\n",
    "                         [87, 82, 81, 80, 74],\n",
    "                         [87, 87, 85, 77, 66],\n",
    "                         [84, 79, 77, 78, 76]]\n",
    "                        ).astype(\"float32\").reshape(1, 5, 5, 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### プーリング1\n",
    "\n",
    "- ウィンドウサイズ: (2, 2)\n",
    "- ストライド: (2, 2)\n",
    "- プーリング: max\n",
    "- (5 -2+1) / 2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83. 83.]\n",
      " [87. 85.]]\n"
     ]
    }
   ],
   "source": [
    "pooled_image = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### プーリング2\n",
    "\n",
    "- ウィンドウサイズ: (2, 2)\n",
    "- ストライド: (1, 1)\n",
    "- プーリング: max\n",
    "- (5 -2+1) / 1 = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83. 82. 83. 83.]\n",
      " [87. 82. 83. 83.]\n",
      " [87. 87. 85. 80.]\n",
      " [87. 87. 85. 78.]]\n"
     ]
    }
   ],
   "source": [
    "pooled_image = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,1,1,1], padding='VALID')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### プーリング3\n",
    "\n",
    "- ウィンドウサイズ: (2, 2)\n",
    "- ストライド: (2, 2)\n",
    "- プーリング: mean\n",
    "- (5 -2+1) / 2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79.5  80.75]\n",
      " [85.75 80.75]]\n"
     ]
    }
   ],
   "source": [
    "pooled_image = tf.nn.avg_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プーリングの演習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# 入力\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "sample_image = np.array([[77, 80, 82, 78, 70, 76, 75],\n",
    "                         [83, 78, 78, 73, 82, 82, 85],\n",
    "                         [87, 82, 81, 80, 74, 88, 70],\n",
    "                         [87, 87, 85, 77, 66, 83, 87],\n",
    "                         [81, 83, 77, 79, 66, 83, 87],\n",
    "                         [87, 87, 83, 70, 66, 83, 87],\n",
    "                         [84, 79, 77, 78, 76, 75, 80]]\n",
    "                        ).astype(\"float32\").reshape(1, 7, 7, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb2b0409940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample_image.reshape(7,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### プーリング1\n",
    "\n",
    "- ウィンドウサイズ: (2, 2)\n",
    "- ストライド: (2, 2)\n",
    "- プーリング: max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83. 82. 82.]\n",
      " [87. 85. 88.]\n",
      " [87. 83. 83.]]\n"
     ]
    }
   ],
   "source": [
    "pooled_image = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')#WRITE ME\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### プーリング2\n",
    "\n",
    "- ウィンドウサイズ: (2, 2)\n",
    "- ストライド: (1, 1)\n",
    "- プーリング: max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83. 82. 82. 82. 82. 85.]\n",
      " [87. 82. 81. 82. 88. 88.]\n",
      " [87. 87. 85. 80. 88. 88.]\n",
      " [87. 87. 85. 79. 83. 87.]\n",
      " [87. 87. 83. 79. 83. 87.]\n",
      " [87. 87. 83. 78. 83. 87.]]\n"
     ]
    }
   ],
   "source": [
    "pooled_image = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,1,1,1], padding='VALID')#WRITE ME\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### プーリング3\n",
    "\n",
    "- ウィンドウサイズ: (2, 2)\n",
    "- ストライド: (2, 2)\n",
    "- プーリング: mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79.5  77.75 77.5 ]\n",
      " [85.75 80.75 77.75]\n",
      " [84.5  77.25 74.5 ]]\n"
     ]
    }
   ],
   "source": [
    "pooled_image = tf.nn.avg_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')#WRITE ME\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 各層クラスの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.  畳み込み層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "活性化関数としてsigmoid関数やtanh関数のような対象な関数を使用する場合は、Xavierの初期化が使われることが多いです。以下の式で表されます。\n",
    "\n",
    "$\\displaystyle U(-\\sqrt{\\frac{6}{n_{\\mathrm{input}} + n_{\\mathrm{output}}}}, \\sqrt{\\frac{6}{n_{\\mathrm{input}} + n_{\\mathrm{output}}}})$\n",
    "\n",
    "$U$: 一様分布、 $ n_{input}$: 入力層のユニット数、$n_{output}$: 出力層のユニット数\n",
    "\n",
    "今回の場合、非対称なReLUを活性化関数として使うので、Heの初期化を使用しています。以下の式で表されます。\n",
    "\n",
    "$\\displaystyle U(-\\sqrt{\\frac{6}{n_{\\mathrm{input}}}}, \\sqrt{\\frac{6}{n_{\\mathrm{input}}}})$\n",
    "\n",
    "$U$: 一様分布、 $ n_{input}$: 入力層のユニット数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ninput: windowのn\n",
    "class Conv:\n",
    "    def __init__(self, filter_shape, function=lambda x: x, strides=[1,1,1,1], padding='VALID'):\n",
    "        # Heの初期値\n",
    "        # filter_shape: (縦の次元数)x(横の次元数)x(入力チャンネル数)x(出力チャンネル数)\n",
    "        fan_in = np.prod(filter_shape[:3])# WRITE ME\n",
    "        fan_out = np.prod(filter_shape[:2]) * filter_shape[3]# WRITE ME\n",
    "        self.W = tf.Variable(rng.uniform(\n",
    "                        low=-np.sqrt(6/fan_in),# WRITE ME,\n",
    "                        high=np.sqrt(6/fan_in),# WRITE ME,\n",
    "                        size=filter_shape\n",
    "                    ).astype('float32'), name='W')\n",
    "        self.b = tf.Variable(np.zeros((filter_shape[3]), dtype='float32'), name='b') # バイアスはフィルタごとなので, 出力フィルタ数と同じ次元数\n",
    "        self.function = function\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "\n",
    "    def __call__(self, x):\n",
    "        u = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding) + self.b#WRITE ME\n",
    "        return self.function(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. プーリング層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID'):\n",
    "        self.ksize = ksize\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return tf.nn.max_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding)#WRITE ME (max pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. 平滑化層（4次元->2次元）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __call__(self, x):\n",
    "        return tf.reshape(x, (-1, np.prod(x.get_shape().as_list()[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. 全結合層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
    "        # He Initialization\n",
    "        # in_dim: 入力の次元数、out_dim: 出力の次元数\n",
    "        self.W = tf.Variable(rng.uniform(\n",
    "                        low=-np.sqrt(6/in_dim),# WRITE ME,\n",
    "                        high=np.sqrt(6/in_dim),# WRITE ME,\n",
    "                        size=(in_dim, out_dim)\n",
    "                    ).astype('float32'), name='W')\n",
    "        self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))\n",
    "        self.function = function\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.function(tf.matmul(x, self.W) + self.b)#WRITE ME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 計算グラフ構築 & パラメータの更新設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今Chapterから `tf` の `Optimizer` が使用可能になります。\n",
    "\n",
    "使い方としては、最小化したい `cost` に対して以下のように学習率を指定することで\n",
    "```\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "```\n",
    "勾配降下法によるパラメータ更新のオペレーションを作成することができます。勾配降下法以外にもAdagrad、Adam等色々あるので、詳しくは公式のドキュメント[[link]](https://www.tensorflow.org/api_guides/python/train)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.log(0)によるnanを防ぐ\n",
    "def tf_log(x):\n",
    "    return tf.log(tf.clip_by_value(x, 1e-10, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "                                                                          \n",
    "h = Conv((5, 5, 1, 20), tf.nn.relu)(x)\n",
    "h = Pooling((1, 2, 2, 1))(h)\n",
    "h = Conv((5, 5, 20, 50), tf.nn.relu)(h)\n",
    "h = Pooling((1, 2, 2, 1))(h)\n",
    "h = Flatten()(h)\n",
    "y = Dense(4*4*50, 10, tf.nn.softmax)(h)\n",
    "\n",
    "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1))\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, Valid Cost: 0.232, Valid Accuracy: 0.930\n",
      "EPOCH: 1, Valid Cost: 0.156, Valid Accuracy: 0.957\n",
      "EPOCH: 2, Valid Cost: 0.120, Valid Accuracy: 0.968\n",
      "EPOCH: 3, Valid Cost: 0.101, Valid Accuracy: 0.971\n",
      "EPOCH: 4, Valid Cost: 0.091, Valid Accuracy: 0.974\n",
      "EPOCH: 5, Valid Cost: 0.082, Valid Accuracy: 0.975\n",
      "EPOCH: 6, Valid Cost: 0.074, Valid Accuracy: 0.979\n",
      "EPOCH: 7, Valid Cost: 0.067, Valid Accuracy: 0.981\n",
      "EPOCH: 8, Valid Cost: 0.068, Valid Accuracy: 0.981\n",
      "EPOCH: 9, Valid Cost: 0.070, Valid Accuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = x_train.shape[0]//batch_size\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        x_train, t_train = shuffle(x_train, t_train, random_state=random_state)\n",
    "        for batch in range(n_batches):\n",
    "            start = batch * batch_size\n",
    "            end = start + batch_size\n",
    "            sess.run(train, feed_dict={x: x_train[start:end], t: t_train[start:end]})\n",
    "        y_pred, cost_valid = sess.run([y, cost], feed_dict={x: x_valid, t: t_valid})\n",
    "        print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
    "            epoch,\n",
    "            cost_valid,\n",
    "            accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
